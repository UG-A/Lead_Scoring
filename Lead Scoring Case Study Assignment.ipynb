{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5818aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress unnecessary warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b776e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the NumPy and Pandas packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "#import stats library\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#import sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,recall_score,roc_auc_score,roc_curve,accuracy_score,precision_score,precision_recall_curve,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#import miscellaneous libraries\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_colwidth\",200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1136b8",
   "metadata": {},
   "source": [
    "### Importing the \"Leads\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb53790e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Leads.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4040\\1217901445.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mleads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Leads.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Leads.csv'"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "leads = pd.read_csv(\"Leads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367957ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the Shape of dataset\n",
    "leads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the different columns in the dataset\n",
    "\n",
    "leads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344307ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the summary of the dataset\n",
    "leads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the info to see the types of the feature variables and the null values present\n",
    "leads.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0bbee7",
   "metadata": {},
   "source": [
    "As it seems that there are quite a few categorical variables present in this dataset for which we will need to create dummy variables. Also, there are a lot of null values present as well, so we will need to treat them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946633b4",
   "metadata": {},
   "source": [
    "## Step 1: Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ea862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the number of missing values in each column\n",
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerous columns exhibit a high number of missing values, rendering them unhelpful. With 9000 data points in our data frame, we confidently eliminate columns with over 3000 missing values as they are of no use to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping all the columns in which greater than \n",
    "for c in leads.columns:\n",
    "    if leads[c].isnull().sum()>3000:\n",
    "        leads.drop(c, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b67379",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of \"City\" column\n",
    "leads['City'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d504e4",
   "metadata": {},
   "source": [
    "`Mumbai` has highest numbers of leads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf89cf9",
   "metadata": {},
   "source": [
    "As you might be able to interpret, the variable `City` won't be of any use in our analysis. So it's best that we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc114df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the \"City\" feature\n",
    "leads.drop(['City'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking value counts of \"Country\" column\n",
    "leads['Country'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef7f77",
   "metadata": {},
   "source": [
    "Highest number of leads from `INDIA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c052c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the \"Country\" feature\n",
    "leads.drop(['Country'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58623b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now checking the percentage of missing values in each column\n",
    "\n",
    "round(100*(leads.isnull().sum()/len(leads.index)), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values again\n",
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88dd04",
   "metadata": {},
   "source": [
    "### Visualizing the features with `Select` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot(x, fig):\n",
    "    plt.subplot(2,2, fig)\n",
    "    sns.countplot(leads[x])\n",
    "    plt.title('Count across'+' '+ x, size = 16)\n",
    "    plt.xlabel(x,size = 14)\n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "countplot('How did you hear about X Education',1)\n",
    "countplot('Lead Profile',2)\n",
    "countplot('Specialization',3)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0492f7c",
   "metadata": {},
   "source": [
    "There are certain columns that contain a level named `'Select'`. This indicates that the student has not made a selection for that specific column, resulting in the display of 'Select'. These values are equivalent to missing values, and it is imperative that we determine the frequency of the 'Select' level in all columns where it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c11580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the value counts of all the columns\n",
    "\n",
    "for c in leads:\n",
    "    print(leads[c].astype('category').value_counts())\n",
    "    print('___________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b1085",
   "metadata": {},
   "source": [
    "The following three columns now have the level 'Select'. Let's check them once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Lead Profile'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23489cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['How did you hear about X Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Specialization'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb03bee",
   "metadata": {},
   "source": [
    "### Visualizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot(x, fig):\n",
    "    plt.subplot(4,2, fig)\n",
    "    sns.countplot(leads[x])\n",
    "    plt.title('Count across'+' '+ x, size = 16)\n",
    "    plt.xlabel(x,size = 14)\n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "plt.figure(figsize=(18,25))\n",
    "\n",
    "\n",
    "countplot('What matters most to you in choosing a course',1)\n",
    "countplot('What is your current occupation',2)\n",
    "countplot('Specialization',3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d2505",
   "metadata": {},
   "source": [
    "As it can be seen that the levels of `\"Lead Profile\"` and `\"How did you hear about X Education\"` have a lot of rows which have the value Select which is of no use to the analysis\n",
    "\n",
    "So it's best that we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping Lead Profile and How did you hear about X Education cols\n",
    "leads.drop(['Lead Profile', 'How did you hear about X Education'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab9f80",
   "metadata": {},
   "source": [
    "We have also noticed that during value count of all the columns, there were few which has one value point present as majority and that is No. So we can drop these following coloums as well. Do Not Call, Search, Magazine, Newspaper Article, X Education Forums, Newspaper, Digital Advertisement, Through Recommendations, Receive More Updates About Our Courses, Update me on Supply Chain Content, Get updates on DM Content, I agree to pay the amount through cheque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.pairplot(leads,diag_kind='kde',hue='Converted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3845da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_edu = leads[['TotalVisits','Total Time Spent on Website','Page Views Per Visit','Converted']]\n",
    "sns.pairplot(x_edu,diag_kind='kde',hue='Converted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dcbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer()\n",
    "transformedx_edu = pd.DataFrame(pt.fit_transform(x_edu))\n",
    "transformedx_edu.columns = x_edu.columns\n",
    "transformedx_edu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34732df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(transformedx_edu,diag_kind='kde',hue='Converted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c31db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the above columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.drop(['Do Not Call', 'Search', 'Magazine', 'Newspaper Article', 'X Education Forums', 'Newspaper', \n",
    "            'Digital Advertisement', 'Through Recommendations', 'Receive More Updates About Our Courses', \n",
    "            'Update me on Supply Chain Content', 'Get updates on DM Content', \n",
    "            'I agree to pay the amount through cheque'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d582ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['What matters most to you in choosing a course'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8320a94a",
   "metadata": {},
   "source": [
    "The variable `What matters most to you in choosing a course` has the `level Better Career Prospects` 6528 times while the other two levels appear once twice and once respectively. \n",
    "\n",
    "So we should dropping this column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96380ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.drop(['What matters most to you in choosing a course'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02bdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values again\n",
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27cd8b",
   "metadata": {},
   "source": [
    "The column `What is your current occupation` contains numerous null values. Although dropping the entire row is an option, we have already lost several feature variables and do not want to risk losing potentially significant data. Therefore, we will only drop the null rows for the `What is your current occupation` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ccc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the null values rows in the column 'What is your current occupation'\n",
    "\n",
    "leads = leads[~pd.isnull(leads['What is your current occupation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing Correlation\n",
    "# figure size\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# heatmap\n",
    "sns.heatmap(leads.corr(), annot=True,cmap=\"BrBG\", robust=True,linewidth=0.1, vmin=-1 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704eabf",
   "metadata": {},
   "source": [
    "### Analysing Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eace455",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = leads.select_dtypes(include =\"object\").columns\n",
    "for i in conv:\n",
    "    \n",
    "    plt.figure(figsize =(15,5))\n",
    "    sns.countplot(leads[i], hue=leads.Converted)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title('Target variable in'+' '+ i)\n",
    "    plt.xlabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values again\n",
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84f4e8",
   "metadata": {},
   "source": [
    "Since now the number of null values present in the columns are quite small we can simply drop the rows in which these null values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ae54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the null values rows in the column 'TotalVisits'\n",
    "\n",
    "leads = leads[~pd.isnull(leads['TotalVisits'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values again\n",
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497adbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the null values rows in the column 'Lead Source'\n",
    "\n",
    "leads = leads[~pd.isnull(leads['Lead Source'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values again\n",
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4438ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null values rows in the column 'Specialization'\n",
    "\n",
    "leads = leads[~pd.isnull(leads['Specialization'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values again\n",
    "leads.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99468be",
   "metadata": {},
   "source": [
    "Now your data doesn't have any null values. Let's now check the percentage of rows that we have retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05564718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(leads.index))\n",
    "print(len(leads.index)/9240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db39a27",
   "metadata": {},
   "source": [
    "We still have around 69% of the rows which seems good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the dataset again\n",
    "\n",
    "leads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d8fea3",
   "metadata": {},
   "source": [
    "Now, clearly the variables `Prospect ID` and `Lead Number` won't be of any use in the analysis, so it's best that we drop these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the \"Prospect ID\" and \"Lead Number\" \n",
    "leads.drop(['Prospect ID', 'Lead Number'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2f454",
   "metadata": {},
   "source": [
    "### Dummy variable creation\n",
    "\n",
    "The next step is to dealing with the categorical variables present in the dataset. So first take a look at which variables are actually categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the columns which are of type 'object'\n",
    "\n",
    "temp = leads.loc[:, leads.dtypes == 'object']\n",
    "temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ba995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Cell\n",
    "df = pd.DataFrame({'P': ['p', 'q', 'p']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df, prefix=['col1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10696ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables using the 'get_dummies' command\n",
    "dummy = pd.get_dummies(df[['Lead Origin', 'Lead Source', 'Do Not Email', 'Last Activity',\n",
    "                              'What is your current occupation', 'A free copy of Mastering The Interview', \n",
    "                              'Last Notable Activity']], drop_first=True)\n",
    "\n",
    "# Add the results to the master DataFrame\n",
    "df = pd.concat([df, dummy], axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variable separately for the variable 'Specialization' since it has the level 'Select' \n",
    "# which is useless so we\n",
    "# drop that level by specifying it explicitly\n",
    "\n",
    "dummy_spl = pd.get_dummies(leads['Specialization'], prefix = 'Specialization')\n",
    "dummy_spl = dummy_spl.drop(['Specialization_Select'], 1)\n",
    "leads = pd.concat([leads, dummy_spl], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f391c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the variables for which the dummy variables have been created\n",
    "\n",
    "leads = leads.drop(['Lead Origin', 'Lead Source', 'Do Not Email', 'Last Activity',\n",
    "                   'Specialization', 'What is your current occupation',\n",
    "                   'A free copy of Mastering The Interview', 'Last Notable Activity'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset again\n",
    "\n",
    "leads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba1932",
   "metadata": {},
   "source": [
    "### Test-Train Split\n",
    "\n",
    "The next step is to spliting the dataset into training an testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the `train_test_split` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8040d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the feature variables in X\n",
    "\n",
    "X = leads.drop(['Converted'], 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = leads['Converted']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset into 70% train and 30% test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9914579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the shape\n",
    "print(\"X_train Size\", X_train.shape)\n",
    "print(\"y_train Size\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61201a7e",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Now there are a few numeric variables present in the dataset which have different scales. So let's go ahead and scale these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec731a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'MinMax scaler' Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9370a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the three numeric features present in the dataset\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.fit_transform(X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3350a",
   "metadata": {},
   "source": [
    "### Looking at the correlations\n",
    "\n",
    "Let's now look at the correlations. Since the number of variables are pretty high, it's better that we look at the table instead of plotting a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the correlation table\n",
    "plt.figure(figsize = (25,15))\n",
    "sns.heatmap(leads.corr())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5aa868",
   "metadata": {},
   "source": [
    "## Step 2: Model Building\n",
    "\n",
    "Now, it's time to move on to model building. With the dataset containing numerous variables that we cannot handle, the most effective approach is to choose a small set of features from this pool of variables using RFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f35144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'LogisticRegression' and creating a LogisticRegression object\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'RFE' and select 15 variables\n",
    "\n",
    "rfe = RFE(logreg, 15)             # running RFE with 15 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219db55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at which features have been selected by RFE\n",
    "\n",
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all the columns selected by RFE in the variable 'col'\n",
    "\n",
    "col = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc1ffd",
   "metadata": {},
   "source": [
    "We have successfully selected all the variables through RFE. As we prioritize the statistical aspect, specifically the p-values and VIFs, we shall utilize these variables to construct a robust logistic regression model with the aid of statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns selected by RFE\n",
    "\n",
    "X_train = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing 'statsmodels'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236c168",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2118f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic Regression model on X_train after adding a constant and output the summary\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "logm2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4477875",
   "metadata": {},
   "source": [
    "There are quite a few variable which have a p-value greater than 0.05. We will need to take care of them. But first, let's also look at the VIFs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0892d3a",
   "metadata": {},
   "source": [
    "### Checking `VIF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'variance_inflation_factor' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be14e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a VIF dataframe for all the variables present\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c1d450",
   "metadata": {},
   "source": [
    "VIFs seem to be in a decent range except for three variables.\n",
    "\n",
    "Let's first drop the variable `Lead Source_Reference` since it has a high p-value as well as a high VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16016f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('Lead Source_Reference', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674f7ca",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534afa2",
   "metadata": {},
   "source": [
    "#### Checking VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783fa824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a VIF dataframe for all the variables present\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de66bd0",
   "metadata": {},
   "source": [
    "The VIFs are now all less than 5. So let's drop the ones with the high p-values beginning with `Last Notable Activity_Had a Phone Conversation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47516bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('Last Notable Activity_Had a Phone Conversation', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e84950",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f516a",
   "metadata": {},
   "source": [
    "Dropping the `What is your current occupation_Housewife` as having high P value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33124dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('What is your current occupation_Housewife', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1def5a4",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97763a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6839089",
   "metadata": {},
   "source": [
    "Droppint hre  `What is your current occupation_Working Professional` as having high P value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ecc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('What is your current occupation_Working Professional', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f054b9",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "res = logm1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ffb844",
   "metadata": {},
   "source": [
    "#### Checking final VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a VIF dataframe for all the variables present\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0dd1cf",
   "metadata": {},
   "source": [
    "## Step 3: Model Evaluation\n",
    "\n",
    "The p-values and VIFs for all variables are satisfactory. Therefore, we can confidently proceed with making predictions using this final set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'predict' to predict the probabilities on the train set\n",
    "\n",
    "y_train_pred = res.predict(sm.add_constant(X_train))\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping it into an array\n",
    "\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552939b",
   "metadata": {},
   "source": [
    "### Creating a dataframe with the actual conversion flag and the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21888e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe containing the actual conversion flag and the probabilities predicted by the model\n",
    "\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78283b6",
   "metadata": {},
   "source": [
    "### Creating new column 'Predicted' with 1 if Paid_Prob > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c60c75",
   "metadata": {},
   "source": [
    "Now that you have the probabilities and have also made conversion predictions using them, it's time to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'metrics' library from sklearn for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fba64",
   "metadata": {},
   "source": [
    "### Creating the `Confusion matrix`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18be3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy\n",
    "\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the other metrics as well\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the 'sensitivity'\n",
    "\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec22b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the 'specificity'\n",
    "\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7206c7",
   "metadata": {},
   "source": [
    "### Finding the Optimal Cutoff\n",
    "0.5 was merely a rough estimate to evaluate the model's performance. To achieve optimal results, it is imperative to optimize the threshold. Therefore, let us begin by plotting a ROC curve to determine the AUC we can attain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC function\n",
    "\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_pred_final.Converted,\n",
    "                    y_train_pred_final.Conversion_Prob, \n",
    "                                         drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb329b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'matplotlib'  to plot the ROC curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8429b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the ROC function\n",
    "\n",
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c33e7",
   "metadata": {},
   "source": [
    "With an impressive area under the curve of 0.86, it's clear that our model is performing exceptionally well. Now, let's confidently explore the sensitivity and specificity tradeoff to determine the optimal cutoff point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dataframe to see the values of accuracy, sensitivity, and specificity at \n",
    "# different values of probabiity cutoffs\n",
    "\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68afaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot it as well\n",
    "\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9e511",
   "metadata": {},
   "source": [
    "As you can see that around `0.42`, you get the optimal values of the three metrics. So let's choose 0.42 as our cutoff now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1005aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.42 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21939a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's checking the `accuracy` now\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the confusion matrix once again\n",
    "\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the other metrics as well\n",
    "\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the 'Sensitivity'\n",
    "\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the 'Specificity'\n",
    "\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc371a",
   "metadata": {},
   "source": [
    "This cutoff point seems good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1934c49",
   "metadata": {},
   "source": [
    "## Step 4: Making Predictions on the Test Set\n",
    "Let's now make predicitons on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab66129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the test set as well using just 'transform'\n",
    "\n",
    "X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] =  scaler.transform(X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675368dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the columns in X_train for X_test as well\n",
    "\n",
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75361fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant to X_test\n",
    "\n",
    "X_test_sm = sm.add_constant(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d24831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking X_test_sm\n",
    "\n",
    "X_test_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the required columns from X_test as well\n",
    "\n",
    "X_test.drop(['Lead Source_Reference', 'What is your current occupation_Housewife', \n",
    "             'What is your current occupation_Working Professional', \n",
    "                     'Last Notable Activity_Had a Phone Conversation'], 1, \n",
    "                                inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set and store it in the variable 'y_test_pred'\n",
    "\n",
    "y_test_pred = res.predict(sm.add_constant(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f212293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove index for both dataframes to append them side by side \n",
    "\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ea6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append y_test_df and y_pred_1\n",
    "\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c4d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 'y_pred_final'\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98566352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column \n",
    "\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60311e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692314a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using 0.45 as the cutoff\n",
    "\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.42 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a20136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy\n",
    "\n",
    "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52542a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619fe0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the 'sensitivity'\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the 'specificity'\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d909d0d8",
   "metadata": {},
   "source": [
    "### Precision-Recall View\n",
    "Let's now also build the training model using the precision-recall view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3be279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the confusion matrix again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e039bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc11157a",
   "metadata": {},
   "source": [
    "#### Precision = \n",
    "         TP / TP + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74962b2",
   "metadata": {},
   "source": [
    "#### Recall = \n",
    "          TP / TP + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cbd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfcc45a",
   "metadata": {},
   "source": [
    "### Precision and recall tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65489810",
   "metadata": {},
   "source": [
    "Importing the `Precision recall curve` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba8005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.Converted, y_train_pred_final.Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.44 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's checking the `accuracy` now\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's creating the confusion matrix once again\n",
    "\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the other metrics as well\n",
    "\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826694a2",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166ef4a",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90875811",
   "metadata": {},
   "source": [
    "This cutoff point seems good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b85df",
   "metadata": {},
   "source": [
    "## Step 5: Making Predictions on the Test Set\n",
    "Let's now make predicitons on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set and store it in the variable 'y_test_pred'\n",
    "\n",
    "y_test_pred = res.predict(sm.add_constant(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b771429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08866a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c134ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f475e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05697155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append y_test_df and y_pred_1\n",
    "\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'y_pred_final'\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12eddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column \n",
    "\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53514d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set using 0.44 as the cutoff\n",
    "\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.44 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef7d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfe452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's checking the overall accuracy\n",
    "\n",
    "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac55221",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c993243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Precision\n",
    "\n",
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a031c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Recall\n",
    "\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f943d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
